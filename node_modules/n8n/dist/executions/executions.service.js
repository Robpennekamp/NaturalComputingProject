"use strict";
var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
};
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.ExecutionsService = void 0;
const jsonschema_1 = require("jsonschema");
const n8n_core_1 = require("n8n-core");
const n8n_workflow_1 = require("n8n-workflow");
const typeorm_1 = require("typeorm");
const ActiveExecutions_1 = require("../ActiveExecutions");
const config_1 = __importDefault(require("../config"));
const NodeTypes_1 = require("../NodeTypes");
const Queue_1 = require("../Queue");
const ResponseHelper = __importStar(require("../ResponseHelper"));
const WorkflowHelpers_1 = require("../WorkflowHelpers");
const WorkflowRunner_1 = require("../WorkflowRunner");
const Db = __importStar(require("../Db"));
const GenericHelpers = __importStar(require("../GenericHelpers"));
const flatted_1 = require("flatted");
const typedi_1 = require("typedi");
const executionHelpers_1 = require("./executionHelpers");
const ExecutionMetadata_1 = require("../databases/entities/ExecutionMetadata");
const DateUtils_1 = require("typeorm/util/DateUtils");
const schemaGetExecutionsQueryFilter = {
    $id: '/IGetExecutionsQueryFilter',
    type: 'object',
    properties: {
        id: { type: 'string' },
        finished: { type: 'boolean' },
        mode: { type: 'string' },
        retryOf: { type: 'string' },
        retrySuccessId: { type: 'string' },
        status: {
            type: 'array',
            items: { type: 'string' },
        },
        waitTill: { type: 'boolean' },
        workflowId: { anyOf: [{ type: 'integer' }, { type: 'string' }] },
        metadata: { type: 'array', items: { $ref: '#/$defs/metadata' } },
        startedAfter: { type: 'date-time' },
        startedBefore: { type: 'date-time' },
    },
    $defs: {
        metadata: {
            type: 'object',
            required: ['key', 'value'],
            properties: {
                key: {
                    type: 'string',
                },
                value: { type: 'string' },
            },
        },
    },
};
const allowedExecutionsQueryFilterFields = Object.keys(schemaGetExecutionsQueryFilter.properties);
class ExecutionsService {
    static async getWorkflowIdsForUser(user) {
        return (0, WorkflowHelpers_1.getSharedWorkflowIds)(user, ['owner']);
    }
    static async getExecutionsCount(countFilter, user, metadata) {
        const dbType = config_1.default.getEnv('database.type');
        const filteredFields = Object.keys(countFilter).filter((field) => field !== 'id');
        if (dbType !== 'postgresdb' ||
            (metadata === null || metadata === void 0 ? void 0 : metadata.length) ||
            filteredFields.length > 0 ||
            user.globalRole.name !== 'owner') {
            const sharedWorkflowIds = await this.getWorkflowIdsForUser(user);
            let query = Db.collections.Execution.createQueryBuilder('execution')
                .select()
                .orderBy('execution.id', 'DESC')
                .where({ workflowId: (0, typeorm_1.In)(sharedWorkflowIds) });
            if (metadata === null || metadata === void 0 ? void 0 : metadata.length) {
                query = query.leftJoinAndSelect(ExecutionMetadata_1.ExecutionMetadata, 'md', 'md.executionId = execution.id');
                for (const md of metadata) {
                    query = query.andWhere('md.key = :key AND md.value = :value', md);
                }
            }
            if (filteredFields.length > 0) {
                query = query.andWhere(countFilter);
            }
            const count = await query.getCount();
            return { count, estimated: false };
        }
        try {
            const estimateRowsNumberSql = "SELECT n_live_tup FROM pg_stat_all_tables WHERE relname = 'execution_entity';";
            const rows = await Db.collections.Execution.query(estimateRowsNumberSql);
            const estimate = parseInt(rows[0].n_live_tup, 10);
            if (estimate > 100000) {
                return { count: estimate, estimated: true };
            }
        }
        catch (error) {
            n8n_workflow_1.LoggerProxy.warn(`Failed to get executions count from Postgres: ${error}`);
        }
        const sharedWorkflowIds = await (0, WorkflowHelpers_1.getSharedWorkflowIds)(user);
        const count = await Db.collections.Execution.count({
            where: {
                workflowId: (0, typeorm_1.In)(sharedWorkflowIds),
            },
        });
        return { count, estimated: false };
    }
    static massageFilters(filter) {
        if (filter) {
            if (filter.waitTill === true) {
                filter.waitTill = (0, typeorm_1.Not)((0, typeorm_1.IsNull)());
            }
            else if (filter.finished === false) {
                filter.waitTill = (0, typeorm_1.IsNull)();
            }
            else {
                delete filter.waitTill;
            }
            if (Array.isArray(filter.metadata)) {
                delete filter.metadata;
            }
            if ('startedAfter' in filter) {
                delete filter.startedAfter;
            }
            if ('startedBefore' in filter) {
                delete filter.startedBefore;
            }
        }
    }
    static async getExecutionsList(req) {
        var _a;
        const sharedWorkflowIds = await this.getWorkflowIdsForUser(req.user);
        if (sharedWorkflowIds.length === 0) {
            return {
                count: 0,
                estimated: false,
                results: [],
            };
        }
        let filter = undefined;
        if (req.query.filter) {
            try {
                const filterJson = (0, n8n_workflow_1.jsonParse)(req.query.filter);
                if (filterJson) {
                    Object.keys(filterJson).map((key) => {
                        if (!allowedExecutionsQueryFilterFields.includes(key))
                            delete filterJson[key];
                    });
                    if ((0, jsonschema_1.validate)(filterJson, schemaGetExecutionsQueryFilter).valid) {
                        filter = filterJson;
                    }
                }
            }
            catch (error) {
                n8n_workflow_1.LoggerProxy.error('Failed to parse filter', {
                    userId: req.user.id,
                    filter: req.query.filter,
                });
                throw new ResponseHelper.InternalServerError('Parameter "filter" contained invalid JSON string.');
            }
        }
        const workflowId = (_a = filter === null || filter === void 0 ? void 0 : filter.workflowId) === null || _a === void 0 ? void 0 : _a.toString();
        if (workflowId !== undefined && !sharedWorkflowIds.includes(workflowId)) {
            n8n_workflow_1.LoggerProxy.verbose(`User ${req.user.id} attempted to query non-shared workflow ${workflowId}`);
            return {
                count: 0,
                estimated: false,
                results: [],
            };
        }
        const limit = req.query.limit
            ? parseInt(req.query.limit, 10)
            : GenericHelpers.DEFAULT_EXECUTIONS_GET_ALL_LIMIT;
        const executingWorkflowIds = [];
        if (config_1.default.getEnv('executions.mode') === 'queue') {
            const queue = typedi_1.Container.get(Queue_1.Queue);
            const currentJobs = await queue.getJobs(['active', 'waiting']);
            executingWorkflowIds.push(...currentJobs.map(({ data }) => data.executionId));
        }
        executingWorkflowIds.push(...typedi_1.Container.get(ActiveExecutions_1.ActiveExecutions)
            .getActiveExecutions()
            .map(({ id }) => id));
        const findWhere = {
            workflowId: (0, typeorm_1.In)(sharedWorkflowIds),
        };
        if (filter === null || filter === void 0 ? void 0 : filter.status) {
            Object.assign(findWhere, { status: (0, typeorm_1.In)(filter.status) });
        }
        if (filter === null || filter === void 0 ? void 0 : filter.finished) {
            Object.assign(findWhere, { finished: filter.finished });
        }
        const rangeQuery = [];
        const rangeQueryParams = {};
        if (req.query.lastId) {
            rangeQuery.push('execution.id < :lastId');
            rangeQueryParams.lastId = req.query.lastId;
        }
        if (req.query.firstId) {
            rangeQuery.push('execution.id > :firstId');
            rangeQueryParams.firstId = req.query.firstId;
        }
        if (executingWorkflowIds.length > 0) {
            rangeQuery.push('execution.id NOT IN (:...executingWorkflowIds)');
            rangeQueryParams.executingWorkflowIds = executingWorkflowIds;
        }
        if (rangeQuery.length) {
            Object.assign(findWhere, {
                id: (0, typeorm_1.Raw)(() => rangeQuery.join(' and '), rangeQueryParams),
            });
        }
        let query = Db.collections.Execution.createQueryBuilder('execution')
            .select([
            'execution.id',
            'execution.finished',
            'execution.mode',
            'execution.retryOf',
            'execution.retrySuccessId',
            'execution.waitTill',
            'execution.startedAt',
            'execution.stoppedAt',
            'execution.workflowData',
            'execution.status',
        ])
            .orderBy('execution.id', 'DESC')
            .take(limit)
            .where(findWhere);
        const countFilter = (0, n8n_workflow_1.deepCopy)(filter !== null && filter !== void 0 ? filter : {});
        const metadata = (0, executionHelpers_1.isAdvancedExecutionFiltersEnabled)() ? filter === null || filter === void 0 ? void 0 : filter.metadata : undefined;
        if (metadata === null || metadata === void 0 ? void 0 : metadata.length) {
            query = query.leftJoin(ExecutionMetadata_1.ExecutionMetadata, 'md', 'md.executionId = execution.id');
            for (const md of metadata) {
                query = query.andWhere('md.key = :key AND md.value = :value', md);
            }
        }
        if (filter === null || filter === void 0 ? void 0 : filter.startedAfter) {
            query = query.andWhere({
                startedAt: (0, typeorm_1.MoreThanOrEqual)(DateUtils_1.DateUtils.mixedDateToUtcDatetimeString(new Date(filter.startedAfter))),
            });
        }
        if (filter === null || filter === void 0 ? void 0 : filter.startedBefore) {
            query = query.andWhere({
                startedAt: (0, typeorm_1.LessThanOrEqual)(DateUtils_1.DateUtils.mixedDateToUtcDatetimeString(new Date(filter.startedBefore))),
            });
        }
        if (filter === null || filter === void 0 ? void 0 : filter.status) {
            Object.assign(filter, { status: (0, typeorm_1.In)(filter.status) });
            Object.assign(countFilter, { status: (0, typeorm_1.In)(filter.status) });
        }
        if (filter) {
            this.massageFilters(filter);
            query = query.andWhere(filter);
        }
        this.massageFilters(countFilter);
        countFilter.id = (0, typeorm_1.Not)((0, typeorm_1.In)(executingWorkflowIds));
        const executions = await query.getMany();
        const { count, estimated } = await this.getExecutionsCount(countFilter, req.user, metadata);
        const formattedExecutions = executions.map((execution) => {
            var _a, _b, _c, _d, _e, _f, _g, _h, _j, _k, _l, _m;
            const nodeExecutionStatus = {};
            let lastNodeExecuted;
            let executionError;
            if (!execution.status) {
                execution.status = (0, executionHelpers_1.getStatusUsingPreviousExecutionStatusMethod)(execution);
            }
            try {
                const data = (0, flatted_1.parse)(execution.data);
                lastNodeExecuted = (_b = (_a = data === null || data === void 0 ? void 0 : data.resultData) === null || _a === void 0 ? void 0 : _a.lastNodeExecuted) !== null && _b !== void 0 ? _b : '';
                executionError = (_c = data === null || data === void 0 ? void 0 : data.resultData) === null || _c === void 0 ? void 0 : _c.error;
                if ((_d = data === null || data === void 0 ? void 0 : data.resultData) === null || _d === void 0 ? void 0 : _d.runData) {
                    for (const key of Object.keys(data.resultData.runData)) {
                        const errors = (_f = (_e = data.resultData.runData[key]) === null || _e === void 0 ? void 0 : _e.filter((taskdata) => { var _a; return (_a = taskdata.error) === null || _a === void 0 ? void 0 : _a.name; })) === null || _f === void 0 ? void 0 : _f.map((taskdata) => {
                            var _a, _b;
                            if (((_a = taskdata.error) === null || _a === void 0 ? void 0 : _a.name) === 'NodeOperationError') {
                                return {
                                    name: taskdata.error.name,
                                    message: taskdata.error.message,
                                    description: taskdata.error.description,
                                };
                            }
                            else {
                                return {
                                    name: (_b = taskdata.error) === null || _b === void 0 ? void 0 : _b.name,
                                };
                            }
                        });
                        Object.assign(nodeExecutionStatus, {
                            [key]: {
                                executionStatus: data.resultData.runData[key][0].executionStatus,
                                errors,
                                data: (_g = data.resultData.runData[key][0].data) !== null && _g !== void 0 ? _g : undefined,
                            },
                        });
                    }
                }
            }
            catch { }
            return {
                id: execution.id,
                finished: execution.finished,
                mode: execution.mode,
                retryOf: (_h = execution.retryOf) === null || _h === void 0 ? void 0 : _h.toString(),
                retrySuccessId: (_j = execution === null || execution === void 0 ? void 0 : execution.retrySuccessId) === null || _j === void 0 ? void 0 : _j.toString(),
                waitTill: execution.waitTill,
                startedAt: execution.startedAt,
                stoppedAt: execution.stoppedAt,
                workflowId: (_l = (_k = execution.workflowData) === null || _k === void 0 ? void 0 : _k.id) !== null && _l !== void 0 ? _l : '',
                workflowName: (_m = execution.workflowData) === null || _m === void 0 ? void 0 : _m.name,
                status: execution.status,
                lastNodeExecuted,
                executionError,
                nodeExecutionStatus,
            };
        });
        return {
            count,
            results: formattedExecutions,
            estimated,
        };
    }
    static async getExecution(req) {
        const sharedWorkflowIds = await this.getWorkflowIdsForUser(req.user);
        if (!sharedWorkflowIds.length)
            return undefined;
        const { id: executionId } = req.params;
        const execution = await Db.collections.Execution.findOne({
            where: {
                id: executionId,
                workflowId: (0, typeorm_1.In)(sharedWorkflowIds),
            },
        });
        if (!execution) {
            n8n_workflow_1.LoggerProxy.info('Attempt to read execution was blocked due to insufficient permissions', {
                userId: req.user.id,
                executionId,
            });
            return undefined;
        }
        if (!execution.status) {
            execution.status = (0, executionHelpers_1.getStatusUsingPreviousExecutionStatusMethod)(execution);
        }
        if (req.query.unflattedResponse === 'true') {
            return ResponseHelper.unflattenExecutionData(execution);
        }
        return execution;
    }
    static async retryExecution(req) {
        const sharedWorkflowIds = await this.getWorkflowIdsForUser(req.user);
        if (!sharedWorkflowIds.length)
            return false;
        const { id: executionId } = req.params;
        const execution = await Db.collections.Execution.findOne({
            where: {
                id: executionId,
                workflowId: (0, typeorm_1.In)(sharedWorkflowIds),
            },
        });
        if (!execution) {
            n8n_workflow_1.LoggerProxy.info('Attempt to retry an execution was blocked due to insufficient permissions', {
                userId: req.user.id,
                executionId,
            });
            throw new ResponseHelper.NotFoundError(`The execution with the ID "${executionId}" does not exist.`);
        }
        const fullExecutionData = ResponseHelper.unflattenExecutionData(execution);
        if (fullExecutionData.finished) {
            throw new Error('The execution succeeded, so it cannot be retried.');
        }
        const executionMode = 'retry';
        fullExecutionData.workflowData.active = false;
        const data = {
            executionMode,
            executionData: fullExecutionData.data,
            retryOf: req.params.id,
            workflowData: fullExecutionData.workflowData,
            userId: req.user.id,
        };
        const { lastNodeExecuted } = data.executionData.resultData;
        if (lastNodeExecuted) {
            delete data.executionData.resultData.error;
            const { length } = data.executionData.resultData.runData[lastNodeExecuted];
            if (length > 0 &&
                data.executionData.resultData.runData[lastNodeExecuted][length - 1].error !== undefined) {
                data.executionData.resultData.runData[lastNodeExecuted].pop();
            }
        }
        if (req.body.loadWorkflow) {
            const workflowId = fullExecutionData.workflowData.id;
            const workflowData = (await Db.collections.Workflow.findOneBy({
                id: workflowId,
            }));
            if (workflowData === undefined) {
                throw new Error(`The workflow with the ID "${workflowId}" could not be found and so the data not be loaded for the retry.`);
            }
            data.workflowData = workflowData;
            const nodeTypes = typedi_1.Container.get(NodeTypes_1.NodeTypes);
            const workflowInstance = new n8n_workflow_1.Workflow({
                id: workflowData.id,
                name: workflowData.name,
                nodes: workflowData.nodes,
                connections: workflowData.connections,
                active: false,
                nodeTypes,
                staticData: undefined,
                settings: workflowData.settings,
            });
            for (const stack of data.executionData.executionData.nodeExecutionStack) {
                const node = workflowInstance.getNode(stack.node.name);
                if (node === null) {
                    n8n_workflow_1.LoggerProxy.error('Failed to retry an execution because a node could not be found', {
                        userId: req.user.id,
                        executionId,
                        nodeName: stack.node.name,
                    });
                    throw new Error(`Could not find the node "${stack.node.name}" in workflow. It probably got deleted or renamed. Without it the workflow can sadly not be retried.`);
                }
                stack.node = node;
            }
        }
        const workflowRunner = new WorkflowRunner_1.WorkflowRunner();
        const retriedExecutionId = await workflowRunner.run(data);
        const executionData = await typedi_1.Container.get(ActiveExecutions_1.ActiveExecutions).getPostExecutePromise(retriedExecutionId);
        if (!executionData) {
            throw new Error('The retry did not start for an unknown reason.');
        }
        return !!executionData.finished;
    }
    static async deleteExecutions(req) {
        const sharedWorkflowIds = await this.getWorkflowIdsForUser(req.user);
        if (sharedWorkflowIds.length === 0) {
            return;
        }
        const { deleteBefore, ids, filters: requestFiltersRaw } = req.body;
        let requestFilters;
        if (requestFiltersRaw) {
            try {
                Object.keys(requestFiltersRaw).map((key) => {
                    if (!allowedExecutionsQueryFilterFields.includes(key))
                        delete requestFiltersRaw[key];
                });
                if ((0, jsonschema_1.validate)(requestFiltersRaw, schemaGetExecutionsQueryFilter).valid) {
                    requestFilters = requestFiltersRaw;
                }
            }
            catch (error) {
                throw new ResponseHelper.InternalServerError('Parameter "filter" contained invalid JSON string.');
            }
        }
        if (!deleteBefore && !ids) {
            throw new Error('Either "deleteBefore" or "ids" must be present in the request body');
        }
        const where = { workflowId: (0, typeorm_1.In)(sharedWorkflowIds) };
        if (deleteBefore) {
            where.startedAt = (0, typeorm_1.LessThanOrEqual)(deleteBefore);
            Object.assign(where, requestFilters);
            if (where.status) {
                where.status = (0, typeorm_1.In)(requestFiltersRaw.status);
            }
        }
        else if (ids) {
            where.id = (0, typeorm_1.In)(ids);
        }
        else
            return;
        const executions = await Db.collections.Execution.find({
            select: ['id'],
            where,
        });
        if (!executions.length) {
            if (ids) {
                n8n_workflow_1.LoggerProxy.error('Failed to delete an execution due to insufficient permissions', {
                    userId: req.user.id,
                    executionIds: ids,
                });
            }
            return;
        }
        const idsToDelete = executions.map(({ id }) => id);
        const binaryDataManager = n8n_core_1.BinaryDataManager.getInstance();
        await Promise.all(idsToDelete.map(async (id) => binaryDataManager.deleteBinaryDataByExecutionId(id)));
        do {
            const batch = idsToDelete.splice(0, 500);
            await Db.collections.Execution.delete(batch);
        } while (idsToDelete.length > 0);
    }
}
exports.ExecutionsService = ExecutionsService;
//# sourceMappingURL=executions.service.js.map